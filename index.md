---
layout: default
title: Home
nav_order: 1
description: "IndicSwipe provides datasets and model architectures for decoding gesture inputs for swipe typing on touch keyboards for over 7 Indic languages."
permalink: /
---

# Gesture Input Decoding for Indic Languages
{: .fs-9 }

Datasets and NLP models for swipe typing on touch keyboards across 7 Indic languages.
{: .fs-6 .fw-300 }

[About the project](##About){: .btn .btn-primary .fs-5 .mb-4 .mb-md-0 .mr-2 } [View it on GitHub](https://github.com/emilbiju/indic_swipe){: .btn .fs-5 .mb-4 .mb-md-0 }
---

## About

IndicSwipe is aimed at developing a keyboard that supports gesture typing on mobile devices for Indic languages. IndicSwipe provides a novel Deep Learning architecture that jointly uses Transformers and LSTMs to accurately decode noisy swipe inputs and has been tested on 7 Indic languages. To further research in this field, we release two datasets that are generated by simulations that model human motor control using the principles of jerk minimization. The models and datasets have been developed to cater to two closely related tasks:

1. **Indic-to-indic Decoding:** To support users who prefer to type in the native Indic script (Devanagari, Bengali, etc.)
2. **English-to-indic Decoding:** To support users who prefer to type using an English script keyboard but want the output in the native script.

IndicSwipe demonstrates high decoding accuracies varying from 70% to 95% on both tasks across 7 languages.

<p align="center">
   <img src="assets/images/gesture_sample.jpg" width=400 height=400>
</p>


### Code of Conduct

IndicSwipe is committed to fostering a welcoming community.

[View our Code of Conduct](https://github.com/pmarsceill/just-the-docs/tree/master/CODE_OF_CONDUCT.md) on our GitHub repository.
